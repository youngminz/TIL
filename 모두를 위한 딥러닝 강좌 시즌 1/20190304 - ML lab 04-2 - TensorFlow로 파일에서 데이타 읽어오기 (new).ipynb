{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  8, 12])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "\n",
    "b[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 11, 12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 11, 12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 11, 12])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[-1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [ 5,  6],\n",
       "       [ 9, 10]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 9.098071098327637\n",
      "Prediction: \n",
      "[[151.87302]\n",
      " [183.25195]\n",
      " [180.03029]\n",
      " [196.76895]\n",
      " [139.58992]\n",
      " [104.54149]\n",
      " [148.48811]\n",
      " [111.62869]\n",
      " [172.52612]\n",
      " [161.73126]\n",
      " [142.55786]\n",
      " [141.29878]\n",
      " [185.15714]\n",
      " [153.02148]\n",
      " [149.39359]\n",
      " [186.61734]\n",
      " [145.10347]\n",
      " [178.27164]\n",
      " [176.30054]\n",
      " [157.90536]\n",
      " [173.78804]\n",
      " [172.70291]\n",
      " [165.43668]\n",
      " [151.24643]\n",
      " [189.35617]]\n",
      "\n",
      "\n",
      "1000 Cost: 6.740566253662109\n",
      "Prediction: \n",
      "[[153.05548 ]\n",
      " [184.78238 ]\n",
      " [181.46942 ]\n",
      " [198.49107 ]\n",
      " [140.65616 ]\n",
      " [105.57846 ]\n",
      " [149.97623 ]\n",
      " [113.007095]\n",
      " [174.1705  ]\n",
      " [163.6058  ]\n",
      " [143.86513 ]\n",
      " [142.69508 ]\n",
      " [186.4873  ]\n",
      " [153.91275 ]\n",
      " [150.92194 ]\n",
      " [188.30782 ]\n",
      " [145.79807 ]\n",
      " [180.13042 ]\n",
      " [177.52722 ]\n",
      " [159.01907 ]\n",
      " [175.49399 ]\n",
      " [174.28268 ]\n",
      " [167.00972 ]\n",
      " [152.07443 ]\n",
      " [190.8522  ]]\n",
      "\n",
      "\n",
      "2000 Cost: 6.533350944519043\n",
      "Prediction: \n",
      "[[152.9915  ]\n",
      " [184.738   ]\n",
      " [181.4005  ]\n",
      " [198.52094 ]\n",
      " [140.54341 ]\n",
      " [105.660286]\n",
      " [150.14496 ]\n",
      " [113.33604 ]\n",
      " [174.26439 ]\n",
      " [163.92714 ]\n",
      " [143.92958 ]\n",
      " [142.81297 ]\n",
      " [186.3092  ]\n",
      " [153.61641 ]\n",
      " [151.10785 ]\n",
      " [188.35977 ]\n",
      " [145.39839 ]\n",
      " [180.39207 ]\n",
      " [177.33571 ]\n",
      " [158.86308 ]\n",
      " [175.6595  ]\n",
      " [174.34125 ]\n",
      " [167.13481 ]\n",
      " [151.76167 ]\n",
      " [190.75172 ]]\n",
      "\n",
      "\n",
      "Your score will be  [[186.79373]]\n",
      "Other scores will be  [[178.14839]\n",
      " [176.18811]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt(\"data-01-test-score.csv\", delimiter=\",\", dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Set up feed_dict variables inside the loop.\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train],\n",
    "        feed_dict={X: x_data, Y: y_data})\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        print(step, f\"Cost: {cost_val}\\nPrediction: \\n{hy_val}\\n\\n\")\n",
    "        \n",
    "# Ask my score\n",
    "print(\"Your score will be \", sess.run(hypothesis, \n",
    "                                      feed_dict={X: [[100, 70, 101]]}))\n",
    "\n",
    "print(\"Other scores will be \", sess.run(hypothesis,\n",
    "                                        feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-3ceea8d285c3>:16: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From <ipython-input-21-3ceea8d285c3>:22: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "# 파일이 너무 커서 메모리에 올리기 어려운 경우, 텐서플로우에서는 Queue Runner 시스템을 만들어 두었음\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    [\"data-01-test-score.csv\"],\n",
    "    shuffle=False,\n",
    "    name=\"filename_queue\"\n",
    ")\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "record_defaults = [[0], [0], [0], [0]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# collect batches of csv in\n",
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# Start populating the filename queue\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    \n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

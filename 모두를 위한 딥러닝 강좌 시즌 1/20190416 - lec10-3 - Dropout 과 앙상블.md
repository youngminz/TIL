# 20190416 - lec10-3 - Dropout 과 앙상블

- Overfitting을 어떻게 알 수 있는가?
    - 한 번도 보지 못한 데이터를 주었을 때 낮은 정확도가 나옴
    - 레이어가 많아질수록 Training Set의 Error Rate는 점점 낮아짐
    - 그러나 Test set를 사용하면 어느 순간까지 떨어지다가 다시 올라감
    - 깊게 만들수록 Overfitting 될 확률이 높아짐
- Solutions for overfitting
    - More training data
    - Regularization
- Regularization
    - weight를 너무 크지 않게 하기
    - `cost + lambda * sigma W^2`
- Dropout
    - 학습에 도움이 되지 않는 셀들을 제거함
    - 쉬게 하고 나머지만 학습하게 함
    - random하게 activate function를 끊어버림
    - 학습할 때에만 Dropout 하며, 실전에서는 Dropout 하지 않아야 함
- Ensemble
    - 독립적으로 뉴럴 네트워크를 만들고, 나중에 합침
    - 적게는 2%, 많게는 4-5% 까지 향상됨
